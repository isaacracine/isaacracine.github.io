}
df
}
usa <- remove_outliers(census[-15], colnames(census[-15]))
#get the corresponding region back
reg <- census %>% filter(row_number() %in% row.names(usa))
table(reg$region)
#######################STANDARDIZE
#lastly we need to standardize
#although most of the variables are percentages,
#such that they can be compared, some variables
#are not, such as population size
vars <- scale(as.matrix(reg[,1:ncol(reg)-1]))
usa_std <- cbind.data.frame(reg[,"region"],vars)
dim(usa_std)
colnames(usa_std)
colnames(usa_std) <- c("region", colnames(usa_std)[-1])#unique(usa_std[,1])
#convert the region values to a factor
usa_std$region <- as.factor(usa_std$region)
#get final colnames and number of obs
nrow(usa_std)
table(usa_std$region)
colnames(usa_std)
#######################DATA ANALYSIS
############EXPLORATORY
#####PCA
#obtain the principal components
us.pc <- princomp(usa_std[-1], cor = T)
#plot the explained variance (scree plot)
plot(us.pc, main = "Scree Plot")
#look at the eigenvalues to see how much
eigval <- us.pc$sdev^2
#determine when the percentage of explained
#variance added by a component is less than 5%
summary(us.pc) #Only first 7 PCs
#but from scree plot the first 2 provided the most amount
#about 46% of the variance is explained in just two components!
#make a dataframe
pc_1_2 <- data.frame(usa_std$region, us.pc$scores[,1], us.pc$scores[,2])
colnames(pc_1_2) <- c("region", "pc1", "pc2")
#make a plot of the PCA results
ggplot(pc_1_2, aes(x = pc1, y = pc2, color = region)) +
geom_point() + theme_bw() + xlab("Principal Component 1") +
ylab("Principal Component 2") +
ggtitle("PCA Census Data \n44% Explained Variance")
#######Biplot
#USED ggbiplot
ggbiplot(us.pc, scale = 1.72, varname.size = 4,
circle.prob = , groups = usa_std$region,  circle = TRUE, size = 2) +
scale_color_discrete(name = '') +
theme_bw() + ggtitle("Biplot of Census Data")
##############DISCRIMINANT
#set the seed so consistent
set.seed(1)
#make train and test split to compare performance
train <- sample(1:nrow(usa_std), 2/3*nrow(usa_std))
test <- usa_std[-train,]
#####Tree
us.tree <- tree(as.factor(region) ~ .,
data = usa_std, subset = train, method = "recursive.partition", split = "deviance")
#summary
summary(us.tree)
#get tree structure
us.tree
#plot tree
plot(us.tree)
text(us.tree,splits=T,all=T)
title("Tree for Determing a County's Region")
#performance on test
test.pred <- predict(us.tree,usa_std[-train,], type = 'class')
table(usa_std[-train, "region"],test.pred,dnn=c("From","Classified into"))
#did not predict any SW correcrly
#accuracy
sum(diag(table(test.pred, usa_std[-train, "region"]))) / nrow(test)
#66.9% accuracy for classification
# K-fold cross-validation
us.tree.cv <- cv.tree(us.tree,FUN=prune.misclass, K = 10)
#plot deviance
plot(us.tree.cv$size,us.tree.cv$dev,type="l",xlab="Number of end nodes",ylab="Deviance", main = "CV Deviance per End Nodes")
#prune tree
us.tree.pr <- prune.misclass(us.tree,best=8)
summary(us.tree.pr)
summary(us.tree.pr)
#plot
plot(us.tree.pr)
text(us.tree.pr,splits=T,all=T)
title("Pruned Tree for Determing a County's Region")
#accuracy of pruned tree
prune.pred <- predict(us.tree.pr,usa_std[-train,], type = 'class')
table(usa_std[-train, "region"],prune.pred, dnn=c("From","Classified into"))
#did not predict any SW correcrly
sum(diag(table(prune.pred, usa_std[-train, "region"]))) / nrow(test)
#accuracy now 65.7%
####Random forest
rf <- randomForest(region ~ ., data = usa_std, metric = 'deviance', cv.fold = 10, ntree = 2000, subset = train, mtry = sqrt(dim(usa_std)[2]-1))
rf <- randomForest(region ~ ., data = usa_std, metric = 'deviance', cv.fold = 10, ntree = 2000, subset = train, mtry = sqrt(dim(usa_std)[2]-1))
library(randomForest)
rf <- randomForest(region ~ ., data = usa_std, metric = 'deviance', cv.fold = 10, ntree = 2000, subset = train, mtry = sqrt(dim(usa_std)[2]-1))
#mtry is the number of variables to sample at each iteration
#check out final model
rf
#see which variables were most important
varImpPlot(rf, main = "Variable Importance from Random Forest")
#performance
rf.pred <- predict(rf, newdata = usa_std[-train,], type = 'class')
table(usa_std[-train, "region"],rf.pred,dnn=c("From","Classified into"))
#accuracy
sum(diag(table(rf.pred, usa_std[-train, "region"]))) / nrow(test)
#the accuracy is now 73.8%
####Discriminat Analysis
us.lda <- lda(region ~ ., data = usa_std, subset = train)
us.lda
#predictions with test
us.pred <- predict(us.lda, newdata = usa_std[-train,], type = 'class')
us.pred
#results
table(usa_std[-train,"region"],us.pred$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[-train,"region"],us.pred$class))) / nrow(test)
#0.720
#predictions with train
us.pred.tr <- predict(us.lda, newdata = usa_std[train,], type = 'class')
table(usa_std[train,"region"],us.pred.tr$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[train,"region"],us.pred.tr$class))) / length(train)
#0.771
#histogram plots
ldahist(us.pred$x[,1], g = usa_std$region)
ldahist(us.pred$x[,2], g = usa_std$region)
ldahist(us.pred$x[,3], g = usa_std$region)
#ggplot
lda_df <- data.frame(region = usa_std[-train, "region"], lda = us.pred$x)
ggplot(lda_df) +
geom_point(aes(lda.LD1, lda.LD2, color = region)) +
theme_bw() + ggtitle("Linear Discriminant Analysis")
#percent separation by the linear discriminant
#functions
#   LD1    LD2    LD3    LD4
#0.5565 0.2872 0.1198 0.0365
#make plot comparing the LDA variables
plot(us.lda,col=as.numeric(usa_std[train,"region"]), main = "Pairwise Comparison of Linear Discriminants for Census Data")
#CV
us.lda.cv <- lda(region ~ ., data = usa_std[train,], CV= T, k = 10)
#performance
table(usa_std[train,"region"],us.lda.cv$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[train,"region"],us.lda.cv$class))) / length(train)
#0.747
#Isaac Samuel Racine
#r0867171
#AMSA Final Project
############PACKAGES################
#Load in the libraries needed
library(usdata)
library(tidyverse)
library(ggplot2)
library(tree)
library(ggbiplot)
library(MASS)
library(sparcl)
library(caret)
library(stats)
library(randomForest)
############DATA LOADING AND CLEANING###############
#load in the data
#you cant see the meaning of the variables here:
#https://cran.r-project.org/web/packages/usdata/usdata.pdf
census <- county_2019
head(census)
nrow(census)
#will investigate if we can determine the region
#a county belongs to from their census data
#the regions were selected based on national geographic sectionings
#https://education.nationalgeographic.org/resource/united-states-regions
#check how many states there are
#must see if DC is considered
unique(census$state)
#create a vector containing the states of each region
north_east <- c("Maine", "New Hampshire", "Vermont",
"Massachusetts", "Rhode Island",
"Connecticut", "New York",
"New Jersey", "Pennsylvania")
south_east <- c("Florida", "Georgia", "Alabama",
"Mississippi", "South Carolina",
"North Carolina", "Tennessee",
"Kentucky", "Virginia", "West Virginia",
"Maryland", "Delaware", "District of Columbia",
"Arkansas", "Louisiana")
midwest <- c("Ohio", "Indiana", "Michigan", "Illinois",
"Wisconsin", "Missouri", "Iowa", "Minnesota",
"North Dakota", "South Dakota", "Nebraska", "Kansas")
south_west <- c("Texas", "Oklahoma", "New Mexico",  "Arizona")
west <- c("Colorado", "Wyoming", "Montana", "Idaho", "Utah",
"Nevada", "California", "Oregon", "Washington",
"Alaska", "Hawaii")
#filter the data into new subsets by their region
ne <- census %>% filter(state %in% north_east)
se <- census %>% filter(state %in% south_east)
mw <- census %>% filter(state %in% midwest)
sw <- census %>% filter(state %in% south_west)
we <- census %>% filter(state %in% west)
#make sure all observations were assigned
if(nrow(ne) + nrow(se) + nrow(mw) + nrow(sw) + nrow(we) == nrow(census))
{
print("All counties assigned!")
}
#append a new column to each dataframe with their region
ne$region <- "NE" #north east
se$region <- "SE" #south east
mw$region <- "MW" #midwest
sw$region <- "SW" #southwest
we$region <- "WE" #west
#combine them
census <- rbind(ne, se, mw, sw, we)
nrow(census)
#table of number of counties in each region
table(census$region)
#drop the state column as this dictates the region a state belongs
#to, so we do not want to use it as an attribute
#this also goes for the fips and name of the county
census <- subset(census, select=-c(state,name, fips))
#we also see the MOE columns, margin of error, we can drop these columns
census <- census %>% dplyr::select(-contains("moe"))
colnames(census)
#check to see the type of data in each attribute
sapply(census, class)
#we see all are numeirc values, besides the region
#these are reported as percentages for the county
#check for NAs:
#rows
sum(!complete.cases(census))
#most of the entries have a NA
#where?
#columns
sapply(census, function(x) sum(is.na(x)))
#we see variables relating to mean_work_travel
#and poverty consist of all of the NA values
#it does not come as a suprise that povery had
#many missing values as many counties do not want
#to appear as "poor"
#although this would be interesting to investigate
#they should be removed to prevent complications
#with later analyses
#they could be imputed, but that's out of the scope
#for this assignment
census <- census %>% dplyr::select(-contains(c("poverty", "mean_work_travel")))
ncol(census) #we still have many variables to work with though
#and now we see that all counties are completed cases
sum(!complete.cases(census))
#remove outliers and nas
colnames(census)
#only retain interesting variables
# [6] "avg_family_size" : average number of individuals in family
# [7] "bachelors" : percentage of bachelor graduates over age 25
# [8] "black" : percentage of population that is black
# [9] "hispanic" : percentage of population that is hispanic
# [10] "household_has_broadband" : percentage of houses with broadband internet
# [18] "households_speak_spanish" : percentage of households speaking spanish
# [19] "housing_mobile_homes" : percentage of mobile homes
# [22] "hs_grad" : percentage of high school graduates over age of 25
# [24] "median_age" : median age
# [25] "median_household_income" : median house hold income
# [33] "pop" : 2019 population
# [35] "unemployment_rate" : percentage of unemployment
# [36] "uninsured" : percentage of uninsured civilians
# [41] "white" : percentage of population that is white
# [43] "region" : geographical region
census <- census[c(6:10, 18, 19, 22, 24, 25, 33, 35, 36, 41,43)]
nrow(census)
ncol(census)
#Check for outliers
#pairsplot
pairs(census[-15], main = "Paired Scatterplots of Census Data")
#REMOVE OUTLIERS
#https://www.statology.org/remove-outliers-from-multiple-columns-in-r/
outliers <- function(x) {
Q1 <- quantile(x, probs=.25)
Q3 <- quantile(x, probs=.75)
iqr = Q3-Q1
upper_limit = Q3 + (iqr*1.5)
lower_limit = Q1 - (iqr*1.5)
x > upper_limit | x < lower_limit
}
remove_outliers <- function(df, cols = names(df)) {
for (col in cols) {
df <- df[!outliers(df[[col]]),]
}
df
}
usa <- remove_outliers(census[-15], colnames(census[-15]))
#get the corresponding region back
reg <- census %>% filter(row_number() %in% row.names(usa))
table(reg$region)
#######################STANDARDIZE
#lastly we need to standardize
#although most of the variables are percentages,
#such that they can be compared, some variables
#are not, such as population size
vars <- scale(as.matrix(reg[,1:ncol(reg)-1]))
usa_std <- cbind.data.frame(reg[,"region"],vars)
dim(usa_std)
colnames(usa_std)
colnames(usa_std) <- c("region", colnames(usa_std)[-1])#unique(usa_std[,1])
#convert the region values to a factor
usa_std$region <- as.factor(usa_std$region)
#get final colnames and number of obs
nrow(usa_std)
table(usa_std$region)
colnames(usa_std)
#######################DATA ANALYSIS
############EXPLORATORY
#####PCA
#obtain the principal components
us.pc <- princomp(usa_std[-1], cor = T)
#plot the explained variance (scree plot)
plot(us.pc, main = "Scree Plot")
#look at the eigenvalues to see how much
eigval <- us.pc$sdev^2
#determine when the percentage of explained
#variance added by a component is less than 5%
summary(us.pc) #Only first 7 PCs
#but from scree plot the first 2 provided the most amount
#about 46% of the variance is explained in just two components!
#make a dataframe
pc_1_2 <- data.frame(usa_std$region, us.pc$scores[,1], us.pc$scores[,2])
colnames(pc_1_2) <- c("region", "pc1", "pc2")
#make a plot of the PCA results
ggplot(pc_1_2, aes(x = pc1, y = pc2, color = region)) +
geom_point() + theme_bw() + xlab("Principal Component 1") +
ylab("Principal Component 2") +
ggtitle("PCA Census Data \n44% Explained Variance")
#######Biplot
#USED ggbiplot
ggbiplot(us.pc, scale = 1.72, varname.size = 4,
circle.prob = , groups = usa_std$region,  circle = TRUE, size = 2) +
scale_color_discrete(name = '') +
theme_bw() + ggtitle("Biplot of Census Data")
##############DISCRIMINANT
#set the seed so consistent
set.seed(1)
#make train and test split to compare performance
train <- sample(1:nrow(usa_std), 2/3*nrow(usa_std))
test <- usa_std[-train,]
#####Tree
us.tree <- tree(as.factor(region) ~ .,
data = usa_std, subset = train, method = "recursive.partition", split = "deviance")
#summary
summary(us.tree)
#get tree structure
us.tree
#plot tree
plot(us.tree)
text(us.tree,splits=T,all=T)
title("Tree for Determing a County's Region")
#performance on test
test.pred <- predict(us.tree,usa_std[-train,], type = 'class')
table(usa_std[-train, "region"],test.pred,dnn=c("From","Classified into"))
#did not predict any SW correcrly
#accuracy
sum(diag(table(test.pred, usa_std[-train, "region"]))) / nrow(test)
#66.9% accuracy for classification
# K-fold cross-validation
us.tree.cv <- cv.tree(us.tree,FUN=prune.misclass, K = 10)
#plot deviance
plot(us.tree.cv$size,us.tree.cv$dev,type="l",xlab="Number of end nodes",ylab="Deviance", main = "CV Deviance per End Nodes")
#prune tree
us.tree.pr <- prune.misclass(us.tree,best=8)
summary(us.tree.pr)
#plot
plot(us.tree.pr)
text(us.tree.pr,splits=T,all=T)
title("Pruned Tree for Determing a County's Region")
#accuracy of pruned tree
prune.pred <- predict(us.tree.pr,usa_std[-train,], type = 'class')
table(usa_std[-train, "region"],prune.pred, dnn=c("From","Classified into"))
#did not predict any SW correcrly
sum(diag(table(prune.pred, usa_std[-train, "region"]))) / nrow(test)
#accuracy now 65.7%
####Random forest
rf <- randomForest(region ~ ., data = usa_std, metric = 'deviance', cv.fold = 10, ntree = 2000, subset = train, mtry = sqrt(dim(usa_std)[2]-1))
#mtry is the number of variables to radnomly sample at each iteration
#check out final model
rf
#see which variables were most important
varImpPlot(rf, main = "Variable Importance from Random Forest")
#performance
rf.pred <- predict(rf, newdata = usa_std[-train,], type = 'class')
table(usa_std[-train, "region"],rf.pred,dnn=c("From","Classified into"))
#accuracy
sum(diag(table(rf.pred, usa_std[-train, "region"]))) / nrow(test)
#the accuracy is now 73.8%
####Linear Discriminant Analysis
us.lda <- lda(region ~ ., data = usa_std, subset = train)
us.lda
#predictions with test
us.pred <- predict(us.lda, newdata = usa_std[-train,], type = 'class')
us.pred
#results
table(usa_std[-train,"region"],us.pred$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[-train,"region"],us.pred$class))) / nrow(test)
#0.720
#predictions with train
us.pred.tr <- predict(us.lda, newdata = usa_std[train,], type = 'class')
table(usa_std[train,"region"],us.pred.tr$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[train,"region"],us.pred.tr$class))) / length(train)
#0.771
#histogram plots
ldahist(us.pred$x[,1], g = usa_std$region)
ldahist(us.pred$x[,2], g = usa_std$region)
ldahist(us.pred$x[,3], g = usa_std$region)
#ggplot
lda_df <- data.frame(region = usa_std[-train, "region"], lda = us.pred$x)
ggplot(lda_df) +
geom_point(aes(lda.LD1, lda.LD2, color = region)) +
theme_bw() + ggtitle("Linear Discriminant Analysis")
#percent separation by the linear discriminant
#functions
#   LD1    LD2    LD3    LD4
#0.5565 0.2872 0.1198 0.0365
#make plot comparing the LDA variables
plot(us.lda,col=as.numeric(usa_std[train,"region"]), main = "Pairwise Comparison of Linear Discriminants for Census Data")
#CV
us.lda.cv <- lda(region ~ ., data = usa_std[train,], CV= T, k = 10)
#performance
table(usa_std[train,"region"],us.lda.cv$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[train,"region"],us.lda.cv$class))) / length(train)
#0.747
#CV
us.lda.cv <- lda(region ~ ., data = usa_std[-train,], CV= T, k = 10)
#performance
table(usa_std[-train,"region"],us.lda.cv$class,dnn=c("From","Classified into"))
#performance
sum(table(usa_std[-train,"region"],us.lda.cv$class,dnn=c("From","Classified into")))
sum(diag(table(usa_std[-train,"region"],us.lda.cv$class))) / nrow(test)
us.qda <- qda(region ~ ., data = usa_std, subset = train)
us.qda
summary(us.qda)
#predictions
us.pred.q <- predict(us.qda, newdata = usa_std[-train,], type = 'class')
us.pred.q
#results
table(usa_std[-train,"region"],us.pred.q$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[-train,"region"],us.pred.q$class))) / nrow(test)
#predictions with train
us.pred.tr.q <- predict(us.qda, newdata = usa_std[train,], type = 'class')
table(usa_std[train,"region"],us.pred.tr.q$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[train,"region"],us.pred.tr.q$class))) / length(train)
#CV
us.qda.cv <- qda(region ~ ., data = usa_std[-train,], CV= T, k = 10)
#performance
table(usa_std[-train,"region"],us.qda.cv$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[-train,"region"],us.qda.cv$class))) / nrow(test)
us.pred.cv.q <- predict(us.qda.cv, newdata = usa_std[-train,], type = 'class')
#plot
partimat(region ~., data = usa_std[train,], method = "qda")
library(klaR)
#plot
partimat(region ~., data = usa_std[train,], method = "qda")
#plot
partimat(region ~., data = usa_std[train,], method = "qda")
#plot
partimat(region ~., data = usa_std[train,c(1,2,3)], method = "qda")
#plot
partimat(region ~., data = usa_std[train,c(1,2,3,4,5,6)], method = "qda")
#plot
partimat(region ~., data = usa_std[train,c('black', 'hs_grad')], method = "qda")
#plot
partimat(region ~., data = usa_std[train,c('black', 'hs_grad', 'region')], method = "qda")
#plot
partimat(region ~., data = usa_std[train,c('black', 'hs_grad', 'uninsured' 'region')], method = "qda")
#plot
partimat(region ~., data = usa_std[train,c('black', 'hs_grad', 'uninsured', 'region')], method = "qda")
#make plot comparing the LDA variables
plot(us.lda,col=as.numeric(usa_std[train,"region"]), main = "Pairwise Comparison of Linear Discriminants for Census Data")
#plot
plot(us.qda,col=as.numeric(usa_std[train,"region"]), main = "Pairwise Comparison of Linear Discriminants for Census Data")
usa.qda
text(us.lda,col=as.numeric(us.pred.q$class),labels=as.numeric(kernel.df$GRP))
eqscplot(us.lda,type="n")
eqscplot(us.pred,type="n")
us.pred
#plot
plot(us.lda.pred,col=as.numeric(usa_std[train,"region"]), main = "Pairwise Comparison of Linear Discriminants for Census Data")
#plot
plot(us.pred,col=as.numeric(usa_std[train,"region"]), main = "Pairwise Comparison of Linear Discriminants for Census Data")
#plot
plot(us.lda,col=as.numeric(usa_std[train,"region"]), main = "Pairwise Comparison of Linear Discriminants for Census Data")
us.qda
decisionplot(us.qda, us_std['region', 'black', 'us_grad'], class = 'region')
decisionplot(us.qda, us_std['region', 'black', 'us_grad'], class = 'region')
partimat(region ~ ., us_std['region', 'black', 'us_grad', 'uninsured'], plot.matrix = TRUE, class = 'region')
partimat(region ~ ., usa_std['region', 'black', 'us_grad', 'uninsured'], plot.matrix = TRUE, class = 'region')
partimat(region ~ ., usa_std['region', 'black', 'us_grad', 'pop'], plot.matrix = TRUE, class = 'region')
partimat(region ~ ., usa_std[, c('region', 'black', 'us_grad')], plot.matrix = TRUE, class = 'region')
partimat(region ~ ., usa_std[train, c('region', 'black', 'us_grad')], plot.matrix = TRUE, class = 'region')
usa_std[train, c('region', 'black', 'us_grad')]
sum(diag(table(usa_std[-train,"region"],us.qda.cv$class))) / nrow(test)
sum(diag(table(usa_std[-train,"region"],us.pred$class))) / nrow(test)
sum(diag(table(usa_std[-train,"region"],us.pred.q$class))) / nrow(test)
sum(diag(table(usa_std[-train,"region"],us.qda.cv$class))) / nrow(test)
sum(diag(table(usa_std[-train,"region"],us.pred$class))) / nrow(test)
#performance
table(usa_std[-train,"region"],us.qda.cv$class,dnn=c("From","Classified into"))
#results
table(usa_std[-train,"region"],us.pred$class,dnn=c("From","Classified into"))
#results
table(usa_std[-train,"region"],us.pred.q$class,dnn=c("From","Classified into"))
sum(diag(table(usa_std[-train,"region"],us.pred.q$class))) / nrow(test)
setwd("C:/Users/isaac/Education/UVM/R/KU/EvoAndQuantGenomics/Task_4")
setwd("C:/Users/isaac/Education/UVM/R/PersonalWebsite/isaacracine.github.io")
library(intallr)
install.packages("installr")
updateR()
library(installr)
updateR()
